{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DS&BDA Lab Assignment 7.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["### Data Science And Big Data Analytics Lab\n","### Assignment : 7\n","### Name : Tanay Nitin Nikam\n","### TE-B-48"],"metadata":{"id":"wYKSE17uVat7"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"LDJSYqTi37Dk","executionInfo":{"status":"ok","timestamp":1651856735488,"user_tz":-330,"elapsed":1784,"user":{"displayName":"TE_B_48_Tanay Nikam","userId":"09211581462046656977"}}},"outputs":[],"source":["import nltk"]},{"cell_type":"code","source":["nltk.download('punkt')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_ncCkwlH4exu","outputId":"5f61bcb7-dcbb-4817-8207-26c361aaaf37","executionInfo":{"status":"ok","timestamp":1651856736927,"user_tz":-330,"elapsed":1451,"user":{"displayName":"TE_B_48_Tanay Nikam","userId":"09211581462046656977"}}},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["from nltk import word_tokenize, sent_tokenize\n","sent = \"I will walk 500 miles and I would walk 500 more, just to be the man who walks a thousand miles to fall down at your door!\"\n","print(word_tokenize(sent))\n","print(sent_tokenize(sent))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6THhz68Y4I3A","outputId":"1320c90a-3df0-4f36-ca68-ebedd3552dd0","executionInfo":{"status":"ok","timestamp":1651856736928,"user_tz":-330,"elapsed":32,"user":{"displayName":"TE_B_48_Tanay Nikam","userId":"09211581462046656977"}}},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["['I', 'will', 'walk', '500', 'miles', 'and', 'I', 'would', 'walk', '500', 'more', ',', 'just', 'to', 'be', 'the', 'man', 'who', 'walks', 'a', 'thousand', 'miles', 'to', 'fall', 'down', 'at', 'your', 'door', '!']\n","['I will walk 500 miles and I would walk 500 more, just to be the man who walks a thousand miles to fall down at your door!']\n"]}]},{"cell_type":"code","source":["nltk.download('stopwords')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fne0PV3RF8KM","outputId":"15f1809d-a146-4fe4-bfee-2b180decc730","executionInfo":{"status":"ok","timestamp":1651856736929,"user_tz":-330,"elapsed":29,"user":{"displayName":"TE_B_48_Tanay Nikam","userId":"09211581462046656977"}}},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["from nltk.corpus import stopwords        # the corpus module is an \n","                                         # extremely useful one. \n","                                         # More on that later.\n","stop_words = stopwords.words('english')  # this is the full list of\n","                                         # all stop-words stored in\n","                                         # nltk\n","token = word_tokenize(sent)\n","cleaned_token = []\n","for word in token:\n","    if word not in stop_words:\n","        cleaned_token.append(word)\n","print(\"This is the unclean version:\", token)\n","print(\"This is the cleaned version:\", cleaned_token)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kd7tjvLGFlxH","outputId":"a30c4daa-d05e-4540-8644-9f7c16580639","executionInfo":{"status":"ok","timestamp":1651856736930,"user_tz":-330,"elapsed":23,"user":{"displayName":"TE_B_48_Tanay Nikam","userId":"09211581462046656977"}}},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["This is the unclean version: ['I', 'will', 'walk', '500', 'miles', 'and', 'I', 'would', 'walk', '500', 'more', ',', 'just', 'to', 'be', 'the', 'man', 'who', 'walks', 'a', 'thousand', 'miles', 'to', 'fall', 'down', 'at', 'your', 'door', '!']\n","This is the cleaned version: ['I', 'walk', '500', 'miles', 'I', 'would', 'walk', '500', ',', 'man', 'walks', 'thousand', 'miles', 'fall', 'door', '!']\n"]}]},{"cell_type":"code","source":["from nltk.stem import SnowballStemmer\n","snowball_stemmer = SnowballStemmer('english')\n","text=\"This is a Demo Text for NLP using NLTK. Full form of NLTK is Natural Language Toolkit\"\n","word_tokens = nltk.word_tokenize(text)\n","stemmed_word = [snowball_stemmer.stem(word) for word in word_tokens]\n","print (stemmed_word)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5g5dsPLgNBmi","outputId":"99d961fb-d379-45f0-be6e-629ea7403c66","executionInfo":{"status":"ok","timestamp":1651856736931,"user_tz":-330,"elapsed":21,"user":{"displayName":"TE_B_48_Tanay Nikam","userId":"09211581462046656977"}}},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["['this', 'is', 'a', 'demo', 'text', 'for', 'nlp', 'use', 'nltk', '.', 'full', 'form', 'of', 'nltk', 'is', 'natur', 'languag', 'toolkit']\n"]}]},{"cell_type":"code","source":["nltk.download('wordnet')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wphbjzlFRfTO","outputId":"9be22e27-7991-42e8-c38d-0a2c1a0dce98","executionInfo":{"status":"ok","timestamp":1651856736931,"user_tz":-330,"elapsed":18,"user":{"displayName":"TE_B_48_Tanay Nikam","userId":"09211581462046656977"}}},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/wordnet.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["from nltk.stem import WordNetLemmatizer\n","#is based on The Porter Stemming Algorithm\n","stopword = stopwords.words('english')\n","wordnet_lemmatizer = WordNetLemmatizer()\n","text = \"the dogs are barking outside. Are the cats in the garden?\"\n","word_tokens = nltk.word_tokenize(text)\n","lemmatized_word = [wordnet_lemmatizer.lemmatize(word) for word in word_tokens]\n","print (lemmatized_word)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BjVK2Bn5RFeK","outputId":"20c0a545-692d-41f5-8aa2-405bc65cb85d","executionInfo":{"status":"ok","timestamp":1651856738438,"user_tz":-330,"elapsed":1522,"user":{"displayName":"TE_B_48_Tanay Nikam","userId":"09211581462046656977"}}},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["['the', 'dog', 'are', 'barking', 'outside', '.', 'Are', 'the', 'cat', 'in', 'the', 'garden', '?']\n"]}]},{"cell_type":"code","source":["nltk.download('averaged_perceptron_tagger')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HGzdHYcoTT8j","outputId":"c94e10f8-e78a-4317-88ff-54d2acc36dc0","executionInfo":{"status":"ok","timestamp":1651856738440,"user_tz":-330,"elapsed":28,"user":{"displayName":"TE_B_48_Tanay Nikam","userId":"09211581462046656977"}}},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["\n","text = \"the dogs are barking outside.\"\n","word = nltk.word_tokenize(text)\n","pos_tag = nltk.pos_tag(word)\n","print (pos_tag)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bfXtsOCcTCkT","outputId":"6326b7d5-2ea4-44a1-e1b6-d96f1a7cf554","executionInfo":{"status":"ok","timestamp":1651856738441,"user_tz":-330,"elapsed":21,"user":{"displayName":"TE_B_48_Tanay Nikam","userId":"09211581462046656977"}}},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["[('the', 'DT'), ('dogs', 'NNS'), ('are', 'VBP'), ('barking', 'VBG'), ('outside', 'IN'), ('.', '.')]\n"]}]},{"cell_type":"code","source":["# import required module\n","from sklearn.feature_extraction.text import TfidfVectorizer\n"],"metadata":{"id":"xLugU9w4m_5d","executionInfo":{"status":"ok","timestamp":1651856738441,"user_tz":-330,"elapsed":17,"user":{"displayName":"TE_B_48_Tanay Nikam","userId":"09211581462046656977"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["\n","d0 = 'demo of dsbda'\n","d1 = 'dsbda lab'\n","d2 = 'lab assignment'\n","\n","series = [d0, d1, d2]\n"],"metadata":{"id":"kIBHZgkAnSeL","executionInfo":{"status":"ok","timestamp":1651856738442,"user_tz":-330,"elapsed":17,"user":{"displayName":"TE_B_48_Tanay Nikam","userId":"09211581462046656977"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["# create object\n","tfidf = TfidfVectorizer()\n","\n","# get tf-df values\n","result = tfidf.fit_transform(series)\n"],"metadata":{"id":"GOYKEwqHnoNZ","executionInfo":{"status":"ok","timestamp":1651856738443,"user_tz":-330,"elapsed":18,"user":{"displayName":"TE_B_48_Tanay Nikam","userId":"09211581462046656977"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["# get indexing\n","print('\\nWord indexes:')\n","print(tfidf.vocabulary_)\n","\n","# display tf-idf values\n","print('\\ntf-idf value:')\n","print(result)\n","\n","# in matrix form\n","print('\\ntf-idf values in matrix form:')\n","print(result.toarray())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h_FRWafbn2-D","outputId":"7eb39a2e-6e44-44db-ee70-3952a18062f6","executionInfo":{"status":"ok","timestamp":1651856738444,"user_tz":-330,"elapsed":18,"user":{"displayName":"TE_B_48_Tanay Nikam","userId":"09211581462046656977"}}},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Word indexes:\n","{'demo': 1, 'of': 4, 'dsbda': 2, 'lab': 3, 'assignment': 0}\n","\n","tf-idf value:\n","  (0, 2)\t0.4736296010332684\n","  (0, 4)\t0.6227660078332259\n","  (0, 1)\t0.6227660078332259\n","  (1, 3)\t0.7071067811865476\n","  (1, 2)\t0.7071067811865476\n","  (2, 0)\t0.7959605415681652\n","  (2, 3)\t0.6053485081062916\n","\n","tf-idf values in matrix form:\n","[[0.         0.62276601 0.4736296  0.         0.62276601]\n"," [0.         0.         0.70710678 0.70710678 0.        ]\n"," [0.79596054 0.         0.         0.60534851 0.        ]]\n"]}]}]}